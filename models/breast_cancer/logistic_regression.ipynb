{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2eb57af6",
   "metadata": {},
   "source": [
    "# Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18acd7e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c55f234",
   "metadata": {},
   "source": [
    "First of all, we load the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "450ea7a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train =  pd.read_parquet('../../data/model_input/train_sets/breast_cancer.parquet')\n",
    "test =  pd.read_parquet('../../data/model_input/validation_sets/breast_cancer.parquet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "17826188",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = train.diagnosis\n",
    "X_train = train.drop(columns=['diagnosis'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d3f345c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test = test.diagnosis\n",
    "X_test = test.drop(columns=['diagnosis'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2235410b",
   "metadata": {},
   "source": [
    "We are going to compute different models varying the penalty terms, if the solver is modified it's due to incompatibility with the penalties that are supported by each one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7b9499b",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24440c5e",
   "metadata": {},
   "source": [
    "Without penalty term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec560c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr = LogisticRegression(penalty=None, max_iter=10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics['LR'] = {\n",
    "    'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n",
    "    'Test_Gini': 2*roc_auc_score(y_test, test_pred)-1,\n",
    "    'Run_Time': time.time() - start_time\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06ef59c5",
   "metadata": {},
   "source": [
    "Adding the $l_2$ term to the cost function: $$ \\frac{1}{2}||\\beta||_2^2 = \\frac{1}{2}\\beta^T\\beta \\ , $$ where $\\beta$ is the vector of coefficients."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c93de813",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr = LogisticRegression(max_iter=10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics['LR_l2'] = {\n",
    "    'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n",
    "    'Test_Gini': 2*roc_auc_score(y_test, test_pred)-1,\n",
    "    'Run_Time': time.time() - start_time\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "404c66ca",
   "metadata": {},
   "source": [
    "Instead of the $l_2$ penalty, the $l_1$ penalty: $$||\\beta||_1=\\sum_{i=1}^n|\\beta_i| \\,$$ where $n$ is the length of $\\beta$, that is, the number of features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7079f8fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "\n",
    "lr = LogisticRegression(penalty='l1', solver='liblinear', max_iter=10000)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "metrics['LR_l1'] = {\n",
    "    'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n",
    "    'Test_Gini': 2*roc_auc_score(y_test, test_pred)-1,\n",
    "    'Run_Time': time.time() - start_time\n",
    "} "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24d2237c",
   "metadata": {},
   "source": [
    "Lastly, the ElasticNet penalty: $$\\frac{1-\\rho}{2}||\\beta||_2^2 + \\rho||\\beta||_1 \\ ,$$ where $\\rho$ is a parameter between 0 and 1 that controls the strength of the $l_1$ and $l_2$ regularizations. Note that if $\\rho=1$, ElasticNet is equivalent to $l_1$ and if $\\rho=0$, is the same as $l_2$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "65873833",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rho in [0.25, 0.5, 0.75]:\n",
    "    start_time = time.time()\n",
    "\n",
    "    lr = LogisticRegression(penalty='elasticnet', solver='saga',l1_ratio=rho, max_iter=10000)\n",
    "    lr.fit(X_train, y_train)\n",
    "\n",
    "    train_pred = lr.predict_proba(X_train)[:, 1]\n",
    "    test_pred = lr.predict_proba(X_test)[:, 1]\n",
    "\n",
    "    metrics['LR_en_'+str(rho)] = {\n",
    "        'Train_Gini': 2*roc_auc_score(y_train, train_pred)-1,\n",
    "        'Test_Gini': 2*roc_auc_score(y_test, test_pred)-1,\n",
    "        'Run_Time': time.time() - start_time\n",
    "    } "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "85c00cfc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Run_Time</th>\n",
       "      <th>Train_Gini</th>\n",
       "      <th>Test_Gini</th>\n",
       "      <th>delta%</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LR</th>\n",
       "      <td>1.663978</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.893484</td>\n",
       "      <td>-10.651629</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_l2</th>\n",
       "      <td>0.765762</td>\n",
       "      <td>0.993528</td>\n",
       "      <td>0.953634</td>\n",
       "      <td>-4.015382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_l1</th>\n",
       "      <td>0.310524</td>\n",
       "      <td>0.994384</td>\n",
       "      <td>0.932331</td>\n",
       "      <td>-6.240347</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_en_0.25</th>\n",
       "      <td>0.823723</td>\n",
       "      <td>0.937901</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>-0.861135</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_en_0.5</th>\n",
       "      <td>0.834715</td>\n",
       "      <td>0.937794</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>-0.849826</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LR_en_0.75</th>\n",
       "      <td>0.873662</td>\n",
       "      <td>0.937794</td>\n",
       "      <td>0.929825</td>\n",
       "      <td>-0.849826</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Run_Time  Train_Gini  Test_Gini     delta%\n",
       "LR          1.663978    1.000000   0.893484 -10.651629\n",
       "LR_l2       0.765762    0.993528   0.953634  -4.015382\n",
       "LR_l1       0.310524    0.994384   0.932331  -6.240347\n",
       "LR_en_0.25  0.823723    0.937901   0.929825  -0.861135\n",
       "LR_en_0.5   0.834715    0.937794   0.929825  -0.849826\n",
       "LR_en_0.75  0.873662    0.937794   0.929825  -0.849826"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metrics_lr = pd.DataFrame.from_dict(metrics, orient='index',columns=['Run_Time', 'Train_Gini', 'Test_Gini'])\n",
    "metrics_lr['delta%'] = 100*(metrics_lr.Test_Gini - metrics_lr.Train_Gini) / metrics_lr.Train_Gini\n",
    "metrics_lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "6ba9d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_lr.to_parquet('../../data/metrics/breast_cancer/logistic_regression.parquet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb742c03",
   "metadata": {},
   "source": [
    "Observe that the worst model is the most basic one in terms of overfitting as we could expect. The ElasticNet models that combine both penalties give truthful models in exchange for less accuracy than the $l_2$ and $l_1$ models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "647c8dae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
